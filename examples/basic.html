<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8" />
  <title>spark.js example</title>
  <style>
    html, body { height: 100%; margin: 0; }
    body { background: #111; }    
    canvas { display: block; width: 100%; height: 100%; }
  </style>
</head>

<body>
  <script type="module">
    import { Spark } from "@ludicon/spark.js";

    const errorMessage = `
      <div style="padding: 2em; font-family: sans-serif; max-width: 600px; margin: 5em auto; text-align: center;">
        <h1>WebGPU Not Supported</h1>
        <p>This demo requires a browser with WebGPU support.</p>
        <p>Please try using <strong>Chrome</strong> or <strong>Edge</strong> with WebGPU enabled, or a recent version of <strong>Safari</strong> on macOS.</p>
        <p>More information: <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebGPU_API" target="_blank">MDN: WebGPU API</a></p>
      </div>`;

    async function initWebGPU() {
      if (!navigator.gpu) {
        document.body.innerHTML = errorMessage;
        throw new Error('WebGPU not supported');
      }

      let adapter = null;
      try {
        adapter = await navigator.gpu.requestAdapter();
      } catch (err) {
        console.error("Error while requesting WebGPU adapter:", err);
      }
      if (!adapter) {
        document.body.innerHTML = errorMessage;
        throw new Error('No appropriate GPUAdapter found');
      }

      // Request WebGPU features that Spark needs.
      const requiredFeatures = Spark.getRequiredFeatures(adapter)
      const device = await adapter.requestDevice({ requiredFeatures });

      const canvas = document.createElement('canvas');
      document.body.appendChild(canvas);

      const context = canvas.getContext('webgpu');
      const canvasFormat = navigator.gpu.getPreferredCanvasFormat();

      context.configure({
        device,
        format: canvasFormat,
        alphaMode: 'opaque',
      });

      return { device, context, canvasFormat };
    }

    // Vertex shader
    const vertexShader = `
      struct Uniforms {
          canvasWidth: f32,
          canvasHeight: f32,
          textureWidth: f32,
          textureHeight: f32,
      }
      @group(0) @binding(0) var<uniform> uniforms: Uniforms;

      struct VertexOutput {
          @builtin(position) position: vec4f,
          @location(0) texCoord: vec2f,
      }

      @vertex
      fn main(@location(0) position: vec2f,
              @location(1) texCoord: vec2f) -> VertexOutput {
          var output: VertexOutput;
          
          // Scale the position to maintain 1:1 aspect ratio
          let aspect = (uniforms.textureHeight * uniforms.canvasWidth) / (uniforms.canvasHeight * uniforms.textureWidth);
          
          let scale = vec2f(
              min(1.0, 1.0 / aspect), 
              max(-1.0, -aspect));
          let scaledPos = position * scale;
          
          output.position = vec4f(scaledPos, 0.0, 1.0);
          output.texCoord = texCoord;
          return output;
      } `;

    // Fragment shader
    const fragmentShader = `
      @group(0) @binding(1) var t_diffuse: texture_2d<f32>;
      @group(0) @binding(2) var s_diffuse: sampler;

      @fragment
      fn main(@location(0) texCoord: vec2f) -> @location(0) vec4f {
          var color = textureSampleLevel(t_diffuse, s_diffuse, texCoord, 0.0).xyz;

          color = select(1.055 * pow(color, vec3f(1.0 / 2.4)) - 0.055, color * 12.92, color <= vec3f(0.0031308));

          return vec4f(color, 1.0);
      }`;

    // Create vertex buffer
    function createVertexBuffer(device) {
      const vertices = new Float32Array([
        // position (x, y), texCoord (u, v)
        -1.0, -1.0, 0.0, 0.0,  // bottom left
        1.0, -1.0, 1.0, 0.0,  // bottom right
        -1.0, 1.0, 0.0, 1.0,  // top left
        1.0, 1.0, 1.0, 1.0   // top right
      ]);

      const vertexBuffer = device.createBuffer({
        size: vertices.byteLength,
        usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST,
      });
      device.queue.writeBuffer(vertexBuffer, 0, vertices);
      return vertexBuffer;
    }

    // Main initialization
    async function init() {
      const { device, context, canvasFormat } = await initWebGPU();

      // Create Spark instance.
      const spark = await Spark.create(device)

      // Create vertex buffer
      const vertexBuffer = createVertexBuffer(device);

      // Create uniform buffer for canvas dimensions
      const uniformBuffer = device.createBuffer({
        size: 16, // 4 floats (width, height)
        usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
      });

      const textureUrl = './assets/kodim23.avif';

      let texture;
      try {
        device.pushErrorScope('validation')
        device.pushErrorScope('internal')

        texture = await spark.encodeTexture(textureUrl);

      } finally {
        const validationError = await device.popErrorScope();
        const internalError = await device.popErrorScope();

        if (validationError) {
          console.error('WebGPU Validation error:', validationError.message);
        }
        if (internalError) {
          console.error('WebGPU Internal error:', internalError.message);
        }
      }

      // Create sampler
      const sampler = device.createSampler({
        magFilter: 'linear',
        minFilter: 'linear',
      });

      // Create bind group layout
      const bindGroupLayout = device.createBindGroupLayout({
        entries: [
          {
            binding: 0,
            visibility: GPUShaderStage.VERTEX,
            buffer: { type: 'uniform' }
          },
          {
            binding: 1,
            visibility: GPUShaderStage.FRAGMENT,
            texture: { sampleType: 'float' }
          },
          {
            binding: 2,
            visibility: GPUShaderStage.FRAGMENT,
            sampler: { type: 'filtering' }
          }
        ]
      });

      // Create pipeline layout
      const pipelineLayout = device.createPipelineLayout({
        bindGroupLayouts: [bindGroupLayout]
      });

      // Create bind group
      const bindGroup = device.createBindGroup({
        layout: bindGroupLayout,
        entries: [
          {
            binding: 0,
            resource: { buffer: uniformBuffer }
          },
          {
            binding: 1,
            resource: texture.createView()
          },
          {
            binding: 2,
            resource: sampler
          }
        ]
      });

      // Create render pipeline
      const pipeline = device.createRenderPipeline({
        layout: pipelineLayout,
        vertex: {
          module: device.createShaderModule({ code: vertexShader }),
          entryPoint: 'main',
          buffers: [{
            arrayStride: 16,
            attributes: [
              {
                // position
                shaderLocation: 0,
                offset: 0,
                format: 'float32x2'
              },
              {
                // texCoord
                shaderLocation: 1,
                offset: 8,
                format: 'float32x2'
              }
            ]
          }]
        },
        fragment: {
          module: device.createShaderModule({ code: fragmentShader }),
          entryPoint: 'main',
          targets: [{
            format: canvasFormat
          }]
        },
        primitive: {
          topology: 'triangle-strip',
          stripIndexFormat: 'uint32'
        }
      });

      // Handle window resize
      function resizeCanvas() {
        const displayWidth = window.innerWidth;
        const displayHeight = window.innerHeight;

        const canvas = document.querySelector('canvas');
        if (canvas.width !== displayWidth || canvas.height !== displayHeight) {
          canvas.width = displayWidth;
          canvas.height = displayHeight;

          // Update uniform buffer with new dimensions
          const uniformData = new Float32Array([displayWidth, displayHeight, texture.width, texture.height]);
          device.queue.writeBuffer(uniformBuffer, 0, uniformData);
        }
      }
      window.addEventListener('resize', resizeCanvas);
      resizeCanvas();

      // Render function
      function render() {
        const commandEncoder = device.createCommandEncoder();
        const renderPass = commandEncoder.beginRenderPass({
          colorAttachments: [{
            view: context.getCurrentTexture().createView(),
            clearValue: { r: 0.0, g: 0.0, b: 0.0, a: 0.0 },
            loadOp: 'clear',
            storeOp: 'store'
          }]
        });

        renderPass.setPipeline(pipeline);
        renderPass.setBindGroup(0, bindGroup);
        renderPass.setVertexBuffer(0, vertexBuffer);
        renderPass.draw(4, 1, 0, 0);
        renderPass.end();

        device.queue.submit([commandEncoder.finish()]);
        requestAnimationFrame(render);
      }

      render();
    }

    init().catch(error => {
      console.error('Error initializing WebGPU:', error);
    });
  </script>
</body>

</html>